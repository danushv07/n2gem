{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the metrics \n",
    "\n",
    "This notebook contains the various procedures followed to evaluate the proposed metrics, density & coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import os \n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\" \n",
    "#!module load git\n",
    "import foolbox as fb\n",
    "import torch\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "import numpy as np\n",
    "from n2gem.metrics import gem_build_coverage, gem_build_density\n",
    "from n2gem.aux_funcs import gem_build_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from util_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the seed generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#print(device); #print(torch.cuda.memory_allocated())\n",
    "#torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    \"\"\"Function to load the mnist\n",
    "        The following transform is aaplied: Normalize:(0.1307,)(0.3081,)\n",
    "    \n",
    "    \"\"\"\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081))\n",
    "    ])\n",
    "    train_set = torchvision.datasets.MNIST('./files/', train=True, download=True, transform=transforms)\n",
    "    test_set = torchvision.datasets.MNIST('./files/', train=False, download=True, transform=transforms)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEDMNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to download the medmnist datasets\n",
    "# change the data_flag accordingly\n",
    "data_flag = 'pathmnist'\n",
    "#data_flag = 'organamnist'\n",
    "#download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the respective dataset images and labels\n",
    "npz_file = np.load('/.medmnist/organamnist.npz') # enter the file path here\n",
    "\n",
    "train_imgs = npz_file['train_images']\n",
    "test_imgs = npz_file['test_images']\n",
    "val_imgs = npz_file['val_images']\n",
    "\n",
    "train_labels = npz_file['train_labels']\n",
    "test_labels = npz_file['test_labels']\n",
    "val_labels = npz_file['val_labels']\n",
    "\n",
    "arr_X_dataset = np.concatenate([train_imgs, test_imgs, val_imgs])\n",
    "arr_Y_dataset = np.concatenate([train_labels, test_labels, val_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the datatransform for the MedMNIST dataset\n",
    "# uncomment the required line for pathMNIST or OrganMNIST\n",
    "data_transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Grayscale(),\n",
    "    #torchvision.transforms.Normalize((0.74,0.53,0.71), (0.12,0.18,0.13)) # pathmnist RGB normalize values\n",
    "    #torchvision.transforms.Normalize((0.4657), (0.2936))  # organmnist\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### form the datset using the ```LoadMed```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadMed(arr_X_dataset, arr_Y_dataset, data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the datasets and stratify split \n",
    "- Combine train and test\n",
    "- form the model_dataset[training+ test] and validation set\n",
    "- obtain training & test set to train on the model from model_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "X_trainset, X_testset, X_validation, y_trainset, y_testset, y_validation = create_dataset(False, 0.03, 0.2, train_set=train_set, test_set=test_set)\n",
    "\n",
    "# pathmnist\n",
    "#X_trainset, X_testset, X_validation, y_trainset, y_testset, y_validation = create_dataset(dataset, 0.05, 0.2)\n",
    "\n",
    "# organmnist\n",
    "#X_trainset, X_testset, X_validation, y_trainset, y_testset, y_validation = create_dataset(dataset, 0.08, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the datasets to Torch.TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set,  model_images, model_labels, validation_set = convert_tensor(X_trainset, X_testset, y_trainset, y_testset, X_validation,  y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model_dataset & validation_set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_images, 'model_images.pt')\n",
    "torch.save(model_labels, 'model_labels.pt')\n",
    "\n",
    "torch.save(X_validation, 'validation_images.pt')\n",
    "torch.save(y_validation, 'validation_labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader for the CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN model\n",
    "\n",
    "- the model architecture for the MedMNIST dataset has been adapted from the MedMNIST repository(https://github.com/MedMNIST/MedMNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameteres from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnNet() #PathNet #OrgNet\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "#print(sum(p.numel() for p in model1.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai classifier\n",
    "- Fastai takes the available device by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoaders(train_loader, test_loader)\n",
    "learn_ = Learner(data, MnNet(), loss_func=F.nll_loss, opt_func=Adam, metrics=[accuracy]) #f1score = F1Score(average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.fit_one_cycle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.unfreeze()\n",
    "learn_.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.fit_one_cycle(8, lr_max=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save the fastai classifier\n",
    "- By default it is saved in the /models folder with .pth extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_.save('./fastai_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the model(fastai) and save it as torch model for foolbox compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = learn_.load('fastai_model')\n",
    "torch.save(model_new.model.state_dict(), 'fastai_model_mnist_weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the respective models for the attack\n",
    "MyModel = MnNet() # MnNet, PathNet, OrgNet\n",
    "\n",
    "# --> for the attack change model to model.eval\n",
    "\n",
    "# mnist\n",
    "MyModel.load_state_dict(torch.load('chkpt_files/fastai_MnNet_weights.pth', map_location=device))\n",
    "\n",
    "#pathmnist\n",
    "#MyModel.load_state_dict(torch.load('chkpt_files/fastai_pathmnist_96_weights.pt', map_location=device)) \n",
    "\n",
    "#organmnist\n",
    "#MyModel.load_state_dict(torch.load('chkpt_files/fastai_organmnist_99_weights.pt', map_location=device)) #organmnist\n",
    "\n",
    "MyModel.eval()\n",
    "#print(MyModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Pytorch model for foolbox attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "preprocess = dict(mean=0.1307, std=0.3081)\n",
    "\n",
    "# pathmnist RGB normalize values\n",
    "#preprocess = dict(mean=[0.74,0.53,0.71], std=[0.12,0.18,0.13], axis=-3)\n",
    "\n",
    "# organmnist\n",
    "#preprocess = dict(mean=0.4657, std=0.2936)\n",
    "\n",
    "bound = (0, 1)\n",
    "original_model = fb.PyTorchModel(MyModel, bounds=bound, preprocessing=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attack with 20 values of epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack2 = fb.attacks.FGSM()\n",
    "epsilon = np.linspace(0.0, 1, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Attack the model'></a>\n",
    "## Attack the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```FGSM attack```\n",
    "- Attack the model using validation_dataset\n",
    "- Stratify split model_set --> mnist, pathmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the the images\n",
    "\n",
    "the images can saved in the ```images``` folder and loaded again for the attack. The ```images``` folder is not included in the repo. for space constrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_images = torch.load('images/model_dataset_images.pt', map_location='cpu').cpu()\n",
    "md_labels = torch.load('images/model_dataset_labels.pt', map_location='cpu').cpu()\n",
    "\n",
    "vali_images = torch.load('images/validation_images.pt', map_location='cpu')\n",
    "vali_labels = torch.load('images/validation_labels.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the ```MNIST``` and ```PathMNIST``` dataset, the model dataset was split into 20,000 & 30,000 images respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the model_dataset to obtain 20000 images for the attack\n",
    "\n",
    "# mnist\n",
    "_, X_images, _, y_labels = train_test_split(md_images.numpy(), md_labels.numpy(), test_size=0.29455, random_state=42, stratify=md_labels.numpy())\n",
    "\n",
    "# pathmnist\n",
    "#_, X_images,_, y_labels = train_test_split(md_images.numpy(), md_labels.numpy(), test_size=0.3, random_state=42, stratify=md_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape and form the model_dataset tensors--> named as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "images = ep.astensor(torch.from_numpy(np.array(X_images)).to(device))\n",
    "#images.shape\n",
    "\n",
    "# pathmnist\n",
    "#images = ep.astensor(torch.from_numpy(np.array(X_images)).to(device)) # 30000 model dataset images\n",
    "#labels = ep.astensor(torch.from_numpy(np.array(y_labels)).to(device))\n",
    "\n",
    "\n",
    "# organmnist\n",
    "#images = ep.astensor(md_images.to(device))\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics- Density & Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the real images\n",
    "real = images.raw.view(images.shape[0], -1)\n",
    "real.shape, type(real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference density & coverage\n",
    "-> model_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images from the validation set\n",
    "gen_validate = torch.from_numpy(np.array(vali_images).reshape(len(vali_images), -1)).to(device)\n",
    "gen_labels = torch.from_numpy(np.array(vali_labels).reshape(-1)).to(device)\n",
    "print(gen_validate.shape)\n",
    "\n",
    "\n",
    "density_validate = gem_build_density(real, real.shape[0], gen_validate, 'indexflatl2')\n",
    "coverage_validate = gem_build_coverage(real, real.shape[0], gen_validate, 'indexflatl2')\n",
    "print(f'density: {density_validate:.5f}, coverage: {coverage_validate:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attack the model using validation dataset\n",
    "\n",
    "- convert the validation_images/labels into ep.tensor for foolbox attack compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_imagesx = ep.astensor(torch.from_numpy(np.array(vali_images)).to(device))\n",
    "vali_labelsx = ep.astensor(torch.from_numpy(np.array(vali_labels).reshape(-1)).to(device))\n",
    "print(vali_imagesx.shape, vali_labelsx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import model_attack\n",
    "adv_vali, adv_info_vali = model_attack(attack2, original_model, vali_imagesx, vali_labelsx, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 1-adv_info_vali.float32().mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Density & Coverage \n",
    "\n",
    "##### Adversarial metric\n",
    "compute the metrics between the model_dataset and generated adv.samples(not the feature space)\n",
    "- model_dataset and validation adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_den = []\n",
    "vali_cov = []\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "\n",
    "    # generated adversarial for each epsilon(convert from eagerpy --> torch and reshape)\n",
    "    gen = adv_vali[i].raw.view(adv_vali[i].shape[0], -1)\n",
    "\n",
    "    # density\n",
    "    vali_den.append(gem_build_density(real, real.shape[0], gen, 'indexflatl2'))\n",
    "\n",
    "    # coverage\n",
    "    vali_cov.append(gem_build_coverage(real, real.shape[0], gen, 'indexflatl2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_accuracy = []\n",
    "for i in range(20):\n",
    "    acc = 1 - adv_info_vali[i, :].raw.cpu().numpy().astype(np.float32).mean(axis=-1)\n",
    "    robust_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Density\")\n",
    "print(f\"Reference: density: {density_validate:.5f}\")\n",
    "density_data = []\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    #print(\"Epsilon: {:.5f}, Accuracy: {:.2f}%, Vali_adv_density: {:.5f}\".format(epsilon[i], robust_accuracy[i], vali_den[i]))\n",
    "    density_data.append([epsilon[i], robust_accuracy[i], vali_den[i].cpu().numpy()])\n",
    "\n",
    "density_data = np.array(density_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the variation of density & coverage between the benign samples and the adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,8))\n",
    "ax[0].plot(epsilon, vali_den, c='b', label='model_vali_adv')\n",
    "ax[0].plot(epsilon, np.repeat(density_validate.cpu().numpy(), len(epsilon)), ls='--', c='r', label='model_vali')\n",
    "ax[0].set_xlabel(\"Epsilon\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[0].set_title(\"FGSM attack\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(epsilon, vali_cov, c='b', label='model_vali_adv')\n",
    "ax[1].plot(epsilon, np.repeat(coverage_validate.cpu().numpy(), len(epsilon)), ls='--', c='r', label='model_vali')\n",
    "ax[1].set_xlabel(\"Epsilon\")\n",
    "ax[1].set_ylabel(\"Coverage\")\n",
    "ax[1].set_title(\"FGSM attack\")\n",
    "ax[1].legend()\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"FGSM_attack_pathmnist_FX_model_vali_den_cov.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coverage\")\n",
    "print(f\"Refernce: coverage: {coverage_validate}\")\n",
    "print(f\"Model_dataset & adversarial samples\")\n",
    "coverage_data = []\n",
    "for i in range(len(epsilon)):\n",
    "    #print(\"Epsilon: {:.5f}, Accuracy: {:.2f}%, Vali_adv_coverage: {:.5f}\".format(epsilon[i], robust_accuracy[i], vali_cov[i]))\n",
    "    coverage_data.append([epsilon[i], robust_accuracy[i], vali_cov[i].cpu().numpy()])\n",
    "\n",
    "coverage_data = np.array(coverage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/write the density_data & coverage_data\n",
    "\n",
    "- info. in each file: \n",
    "    - type of attack with model (FX- corresponds to feature extracted computation of metrics)\n",
    "    - attack model with model_dataset -> model_dataset & adversarial samples\n",
    "    - Column: Epsilon | Model_accuracy after attack | Metric between model_dataset & adv. samples \n",
    "    - Metric between model_dataset and validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(<f_name>, 'w') as newfile:\n",
    "    newfile.write(\"# FGSM attack NewNet model with FX model_dataset(30000 images)\" + \"\\n\" +\n",
    "                 \"# and validation_images(5329) 20 epsilon\" + \"\\n\" +\n",
    "                 \"# Epsilon Model_accuracy FX_Vali_adv_density\" + \"\\n\" +\n",
    "                 \"# FX_Model_dataset & FX_validation set: \" + str(density_validate.cpu().numpy()) + \"\\n\" )\n",
    "\n",
    "with open(<f_name>, 'w') as newfile:\n",
    "    newfile.write(\"# FGSM attack NewNet model with FX model_dataset(30000 images)\" + \"\\n\" +\n",
    "                 \"# and validation_images(5329) 20 epsilon\" + \"\\n\" +\n",
    "                 \"# Epsilon Model_accuracy  FX_Vali_adv_coverage\" + \"\\n\" +\n",
    "                 \"# FX_Model_dataset & FX_validation set: \" + str(coverage_validate.cpu().numpy()) + \"\\n\")\n",
    "with open(<f_name>, 'a') as addfile:\n",
    "    np.savetxt(addfile, density_data)\n",
    "    \n",
    "with open(<f_name>, 'a') as addfile:\n",
    "    np.savetxt(addfile, coverage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture of adv. samples\n",
    "\n",
    "- the analysis on the mixture of adv. samples into benign samples for FGSM attack\n",
    "- random mixture of adv. samples into benign samples(validation_set) --> mixture dataset\n",
    "- proportionate quantities: 25%, 50%, 75%\n",
    "- compute metrics between the model_dataset and the created mixture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the no. of validation samples and the split size\n",
    "xx = np.random.choice(np.arange(<vali_sample_size>), size=int(<split_size>*<vali_sample_size>), replace=False)\n",
    "mask = np.zeros(2100, dtype=np.bool)\n",
    "mask[xx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali25_den=[]; vali25_cov=[]\n",
    "\n",
    "for i in range(len(epsilon)):\n",
    "    # for random mixing\n",
    "    adv_vali25_imgs = adv_vali[i].raw[mask]\n",
    "    total_vali_set = torch.cat([vali_imagesx.raw[~mask], adv_vali25_imgs])\n",
    "    \n",
    "    gen = total_vali_set.view(total_vali_set.shape[0], -1)\n",
    "    \n",
    "    # density\n",
    "    vali25_den.append(gem_build_density(real, real.shape[0], gen, 'indexflatl2'))\n",
    "    \n",
    "    # coverage\n",
    "    vali25_cov.append(gem_build_coverage(real, real.shape[0], gen, 'indexflatl2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics25 = []\n",
    "for i in range(len(epsilon)):\n",
    "    metrics25.append([epsilon[i], robust_accuracy[i], vali25_den[i].cpu().numpy(), vali25_cov[i].cpu().numpy()])\n",
    "    \n",
    "metrics25 = np.array(metrics25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FGSM_attack_mnist_NewNet_50randmix_valiadv.dat', 'w') as newfile:\n",
    "    newfile.write(\"# FGSM attack NewNet model with model_dataset(20000 images)\" + \"\\n\" +\n",
    "                 \"# and validation_images(2100) 20 epsilon\" + \"\\n\" +\n",
    "                 \"# 50% mix of adv vali samples random\" + \"\\n\" +\n",
    "                 \"# Epsilon model_acc Vali25_adv_den Vali25_adv_cov\" + \"\\n\" )\n",
    "                 \n",
    "with open('FGSM_attack_mnist_NewNet_50randmix_valiadv.dat', 'a') as addfile:\n",
    "    np.savetxt(addfile, metrics25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```Boundary attack``` on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attack works fine i.e, adversarial samples are created if epsilon is assigned as None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack the model using entire validation_dataset\n",
    "\n",
    "- the Boundary Attack cannot be implemented if the starting images are not adversaries\n",
    "- to create these adversarial samples, ```init_attack``` needs to be specified\n",
    "- any of the attacks inherited from ```Minimization Attack``` can be used for this purpose\n",
    "- all the initial samples should be strictly adversarial samples\n",
    "\n",
    "##### Two different attacks were experimented\n",
    "- ```SaltandPepper```, ```LinearSearchBlendedUniformNoiseAttack```\n",
    "- modify the hyperparameters within these attacks to generate the adversarial samples\n",
    "- the generated samples are given as the starting points for the ```BoundaryAttack```\n",
    "- time complexity increases with changing these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images from the Attack the model section\n",
    "\n",
    "vali_attk_images = ep.astensor(torch.from_numpy(np.array(vali_images)).to(device))\n",
    "vali_attk_labels = ep.astensor(torch.from_numpy(np.array(vali_labels)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_attk_images.shape, type(vali_attk_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BdyAttack = fb.attacks.BoundaryAttack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform init_attack\n",
    "\n",
    "- attack using ```s_attack``` or ```n_attack``` with the validation_set \n",
    "- generate adv. samples --> ```adv_lsbu```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attack = fb.attacks.SaltAndPepperNoiseAttack(steps=5000, across_channels=True)\n",
    "n_attack = fb.attacks.LinearSearchBlendedUniformNoiseAttack(steps=2000, directions=3000)\n",
    "_, adv_lsbu, adv_bdy_info = n_attack(original_model, vali_attk_images, vali_attk_labels.reshape(-1), epsilons=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_bdy_info.float32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"acc: {1 - adv_bdy_info.float32().mean(axis=-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Boundary attack\n",
    "\n",
    "- use the generated adv. images as ```starting_pooint``` for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, adv_bdy, adv_bdy_info = BdyAttack(original_model, vali_attk_images, vali_attk_labels, epsilons=None) #starting_points=adv_lsbu,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Density & Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_attk_images.shape, vali_attk_labels.shape, md_images.shape#, real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real = md_images.view(md_images.shape[0], -1).to(device)\n",
    "# images from the validation set\n",
    "# for pathmnist 30000 model_dataset images are used \n",
    "gen_validate = vali_attk_images.raw.view(vali_attk_images.shape[0], -1)\n",
    "real = images.raw.view(images.shape[0], -1).to(device)\n",
    "\n",
    "density_validate = gem_build_density(real, real.shape[0], gen_validate, 'indexflatl2')\n",
    "coverage_validate = gem_build_coverage(real, real.shape[0], gen_validate, 'indexflatl2')\n",
    "print(density_validate, coverage_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial metric\n",
    "model_dataset & validation_dataset adversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_adv_val = adv_bdy.raw.view(adv_bdy.shape[0], -1)\n",
    "\n",
    "model_density_val = gem_build_density(real, real.shape[0], gen_adv_val, 'indexflatl2')\n",
    "model_coverage_val = gem_build_coverage(real, real.shape[0], gen_adv_val, 'indexflatl2')\n",
    "\n",
    "print(model_density_val, model_coverage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Density\")\n",
    "print(f\"Reference: density: {density_validate:.5f}\")\n",
    "print(f\"Adv: density: {model_density_val:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture of adv. samples\n",
    "\n",
    "- random mixture of adv. samples into validation_set\n",
    "- compute metrics between mixture_set and model_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali25_den=[]; vali25_cov=[]\n",
    "xx = np.random.choice(np.arange(<vali_sample_size>), size=int(<mix_size>*<vali_sample_size>), replace=False)\n",
    "#yy = np.random.choice(np.arange(4708), size=int(0.75*4708), replace=False)\n",
    "mask = np.zeros(<vali_sample_size>, dtype=np.bool)\n",
    "mask[xx] = True\n",
    "\n",
    "# for random mixing\n",
    "adv_vali25_imgs = adv_bdy.raw[mask]\n",
    "total_vali_set = torch.cat([vali_attk_images.raw[~mask], adv_vali25_imgs])\n",
    "\n",
    "gen = total_vali_set.view(total_vali_set.shape[0], -1)\n",
    "\n",
    "# density\n",
    "vali25_den = gem_build_density(real, real.shape[0], gen, 'indexflatl2')\n",
    "\n",
    "# coverage\n",
    "vali25_cov= gem_build_coverage(real, real.shape[0], gen, 'indexflatl2')\n",
    "print(vali25_den, vali25_cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-n2gem",
   "language": "python",
   "name": "n2gem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
